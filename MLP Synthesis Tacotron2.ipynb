{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv8YctTyb_Zu"
      },
      "source": [
        "# **MLP Synthesis**\n",
        "<img src=\"https://media2.giphy.com/media/Ld82Eprf6gkLe/giphy.gif\" width=\"200px\" alt=\"yay!\">\n",
        "\n",
        "\n",
        "### Works on tensorflow 2!\n",
        "\n",
        "-----------------------------------------------------------\n",
        "Here you can test out the TTS voices. If you use google colab, open in Playground (need to be signed in), follow the instructions in each section and run the code by hovering over the cells and clicking the play button.\n",
        "\n",
        "**Note**: Sometimes the models will have a hard time pronouncing stuff, so make sure to use ARPAbet. You can also try to spell words differently to get the TTS to pronounce it. \n",
        "\n",
        "Make sure to wrap the ARPAbet like this: {T EH1 S T}\n",
        "\n",
        "**ARPAbet Translator (Show Lexical Stress)**: http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
        "\n",
        "OR\n",
        "\n",
        "**Merged Dictionary**: https://drive.google.com/open?id=13ciybUBArMtk4fBPcQnVIjkFrGzpkN0E\n",
        "\n",
        "-----------------------------------------------------------\n",
        "\n",
        "Original notebook made by Cookie. Upgrade by g.d."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run cells below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "print('You gpu is:')\n",
        "!nvidia-smi --query-gpu=gpu_name,memory.total --format=csv\n",
        "import os\n",
        "os.getcwd()\n",
        "if os.path.exists('train.py') and os.path.exists('hparams.py'):\n",
        "    %cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if you are a programmer, run this. It will reload all modified files outside this notebook when changed.\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import sys\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import torch\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q gdown\n",
        "!pip install -q matplotlib\n",
        "!pip install -q librosa\n",
        "!pip install -q unidecode\n",
        "!pip install -q mega.py\n",
        "!pip install -q PySoundFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "git_repo_url = 'https://github.com/ghostdancing/tacotron2-tf2.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]    \n",
        "!git clone {git_repo_url}\n",
        "\n",
        "os.mkdir(join(project_name, 'models'))\n",
        "os.mkdir(join(project_name, 'infer'))\n",
        "\n",
        "sys.path.append(join(project_name, 'waveglow/'))\n",
        "sys.path.append(project_name)\n",
        "\n",
        "gdrive_prefix = 'https://drive.google.com/uc?id='"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# install mega, works on windows too\n",
        "if not exists('mega.py'):\n",
        "    print('Downloading mega.py repo')\n",
        "    !git clone https://github.com/ghostdancing/mega.py\n",
        "os.chdir('mega.py/src/')\n",
        "from mega import Mega\n",
        "os.chdir('../../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "GHIBEHtW-eHZ",
        "outputId": "130d5eaa-c073-4025-edb5-cb3340759c6d"
      },
      "outputs": [],
      "source": [
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT\n",
        "from audio_processing import griffin_lim\n",
        "from text import text_to_sequence\n",
        "from denoiser import Denoiser\n",
        "from unidecode import unidecode\n",
        "from random import choice\n",
        "import librosa\n",
        "from colab_utils import ARPA, plot_data, waveglow_gdrive_ids\n",
        "import colab_utils\n",
        "import shutil\n",
        "import soundfile as sf\n",
        "\n",
        "mega = Mega()\n",
        "mega_login = mega.login() # anonymous account\n",
        "mega_login.download_url(colab_utils.arpa_dictionary_mega_url, project_name)\n",
        "\n",
        "if not exists(join(project_name, 'merged.dict.txt')):\n",
        "    colab_utils.download_arpa_dict(project_name)\n",
        "thisdict = colab_utils.get_arpa_dict(join(project_name, 'merged.dict.txt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnRd8RqdT8V"
      },
      "source": [
        "## Setup Tacotron 2 Model\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ng7sqJ4S_MWm",
        "outputId": "38e9b381-ea6d-4aa6-cee9-623d35dd4119"
      },
      "outputs": [],
      "source": [
        "last_model_id = None\n",
        "def load_tacotron2(model_id = r'1Q4lNU_qwiKZvjKZ4kIalt6DACkZRdNPj'):\n",
        "    global last_model_id, model, hparams\n",
        "    if model_id == last_model_id:\n",
        "        return\n",
        "    last_model_id = model_id\n",
        "    # Download Tacotron 2 Model\n",
        "    force_download_TT2 = False\n",
        "    tacotron2_pretrained_model = join(project_name, 'models', model_id)\n",
        "    if not exists(tacotron2_pretrained_model) or force_download_TT2:\n",
        "        gdown.download(gdrive_prefix + model_id, tacotron2_pretrained_model, quiet=False); print(\"Tacotron2 Model Downloaded\")\n",
        "\n",
        "    # Setup Parameters\n",
        "    hparams = create_hparams()\n",
        "    hparams.sampling_rate = 48000\n",
        "    hparams.max_decoder_steps = 3000 # how many steps before cutting off generation, too many and you may get CUDA errors.\n",
        "    hparams.gate_threshold = 0.30 # Model must be 30% sure the clip is over before ending generation\n",
        "    # Load Tacotron2 model into GPU\n",
        "\n",
        "    state = torch.load(tacotron2_pretrained_model)\n",
        "    model = Tacotron2(hparams)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    _ = model.cuda().eval().half()\n",
        "    print(\"This Tacotron model has been trained for \", state['iteration'],\" Iterations.\")\n",
        "\n",
        "load_tacotron2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjFCmJIe1JBT"
      },
      "source": [
        "## Setup WaveGlow Model\n",
        "----\n",
        "**This section does not need to be modified unless you see \"`WaveGlow failed to download on all ID's provided`\" on the output.**\n",
        "\n",
        "---\n",
        "\n",
        "Right now Google may deny permissions, presumably too many downloads.\n",
        "Goto [this](https://drive.google.com/uc?id=1p-GmnYiSS9UsRjw13kkhbIoD0-9t8ALH) link and you can clone the file into your down drive. Click 'Get Sharable Link' and extract the id.\n",
        "\n",
        "`https://drive.google.com/open?id=1DMyL3RxFqAVhH60VCLnVaDt2YJb2RCfz`\n",
        "\n",
        "In this example, the id is `1DMyL3RxFqAVhH60VCLnVaDt2YJb2RCfz`. That can be added to the waveglow_ids list or just replace one of the ids already there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "bzEfJ_ey0SJ5",
        "outputId": "470d8d61-dbe2-45b9-ccb1-fbff6234a5d9"
      },
      "outputs": [],
      "source": [
        "# Download WaveGlow Model\n",
        "waveglow_pretrained_model = join(project_name, 'models/waveglow.pt')\n",
        "waveglow_ids = waveglow_gdrive_ids\n",
        "while not exists(waveglow_pretrained_model) and waveglow_ids:\n",
        "    id = choice(waveglow_ids)\n",
        "    gdown.download(gdrive_prefix + id, waveglow_pretrained_model, quiet=False)\n",
        "    if not exists(waveglow_pretrained_model):\n",
        "        print(\"Download Failed, attempting another ID\"); waveglow_ids.remove(id)\n",
        "\n",
        "if exists(waveglow_pretrained_model): print(\"WaveGlow Downloaded\")\n",
        "else: print(\"WaveGlow failed to download on all ID's provided\")\n",
        "\n",
        "# Load WaveGlow model into GPU\n",
        "state = torch.load(waveglow_pretrained_model)\n",
        "waveglow = state['model']\n",
        "waveglow.cuda().eval().half()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "denoiser = Denoiser(waveglow)\n",
        "print(\"This WaveGlow model has been trained for \", state['iteration'], \" Iterations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic2y4Qh9fslL"
      },
      "source": [
        "## Start playing around with the model\n",
        "\n",
        "Replace `text` with whatever you want.\n",
        "\n",
        "Output files can be found in the tacotron-tf2/infer directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yun2vG6Kf9Jv"
      },
      "source": [
        "**Note**: Sometimes the model won't generate the text perfectly, or sometimes you won't get the emotion you want. If that happens, try re-generating it.\n",
        "\n",
        "Also the model can't handle really, really long text. It can handle some long text, but anything really long, you'll have to break it up into parts.\n",
        "\n",
        "To change the model. Copy the ID for the selected model into the drive_id shown below and continue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0La3cJyKEzly",
        "outputId": "be64fb82-9882-40c8-83bb-6c87117aab21"
      },
      "outputs": [],
      "source": [
        "drive_id = '1Q4lNU_qwiKZvjKZ4kIalt6DACkZRdNPj' # gdrive id of a model\n",
        "\n",
        "text = \"\"\"\n",
        "You have to be careful with this stuff or it'll explode. I think. It's like the writer only wrote down the parts of the spell he thought he'd forget.\n",
        "The FitnessGram Pacer Test is a multistage aerobic capacity test that progressively gets more difficult as it continues.\n",
        "The 20 meter pacer test will begin in 30 seconds. Line up at the start. \n",
        "Ever since Anon arrived in Equestria, Twilight's been getting crazier and crazier.\n",
        "\"\"\"\n",
        "\n",
        "sigma = 0.75\n",
        "denoise_strength = 0.01\n",
        "raw_input_ = False  # disables automatic ARPAbet conversion, useful for inputting your own pronounciation or just for testing \n",
        "\n",
        "show_graphs = True\n",
        "colab_utils.graph_scale = 0.5 # literally a zoom factor\n",
        "colab_utils.alignment_graph_width = 1800\n",
        "colab_utils.alignment_graph_height = 720\n",
        "colab_utils.colormap = 'twilight' #inferno # color map for the spectogram and alignment\n",
        "\n",
        "save_wavs = 1\n",
        "counter = 0\n",
        "text = unidecode(text) # convert unicode punctuation into it's normal equivalents (thanks Fimfiction.)\n",
        "text = text * 1 # how many times to generate each clip\n",
        "load_tacotron2(drive_id)\n",
        "with torch.no_grad():\n",
        "    for i in text.split(\"\\n\"):\n",
        "        if len(i) < 1: continue\n",
        "        print('text:'.ljust(20), i)\n",
        "        if raw_input_:\n",
        "            if i[-1] != \"␤\": i=i+\"␤\" \n",
        "        else:\n",
        "            i = ARPA(i)\n",
        "            print('arpa conversion:'.ljust(20), i)\n",
        "        sequence = np.array(text_to_sequence(i, ['english_cleaners']))[None, :]\n",
        "        sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
        "        mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "        if show_graphs:\n",
        "            plot_data((mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "                alignments.float().data.cpu().numpy()[0].T))\n",
        "        audio = waveglow.infer(mel_outputs_postnet, sigma=sigma); print(\"\"); ipd.display(ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate))\n",
        "        audio_denoised = denoiser(audio, strength=denoise_strength)[:, 0]; print(\"Denoised\"); ipd.display(ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate))\n",
        "        if save_wavs:\n",
        "\n",
        "            sf.write(join(project_name, 'infer', F'tt2_{time.time()}.wav'), np.swapaxes(audio_denoised.cpu().numpy(),0,1), hparams.sampling_rate)\n",
        "            #librosa.output.write_wav('tacotron2/infer/Inf_' + str(counter) + '.wav', ,)\n",
        "        counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hoVyK09oc8z"
      },
      "source": [
        "---\n",
        "\n",
        "The rest is just examples of good alignment. See to the graphs on the right?\n",
        "\n",
        "Those graphs need to look as close to this \n",
        "\n",
        "![Image of Alignment Graph. Basically Perfect alignment, there's no point going above this level](https://i.ibb.co/TKSQz7h/perfect-alignment.png)\n",
        "\n",
        "as possible."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b636ba10171801f307a9a0e9bbe1f02371fe032578d799a814391f959be5c379"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
